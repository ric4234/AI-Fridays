{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EuzaOQns_-f"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ric4234/AI-Fridays/blob/main/Analisi%20Di%20Testi/02_NLP_Chatbot.ipynb\" target=\"_parent\\\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Chatbot using Transformers\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9J0-Rp-6c95M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics and it is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches (https://en.wikipedia.org/wiki/Natural_language_processing). Transformers introduced a significant improvement in this field, starting from Attention Is All You Need paper in 2017 (https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "The goal of this exercise is to build a chatbot using the transformers library (in particular the pipeline function).\n",
        "In order to do that, we will use blenderbot-400M-distill open source model, which was built by Meta https://huggingface.co/facebook/blenderbot-400M-distill.\n",
        "\n",
        "We decided to use this model because it is very small (only 400M parameters) and performs quite well.\n",
        "\n"
      ],
      "metadata": {
        "id": "X5vwStcT6KPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 - Install dependencies and create utils functions"
      ],
      "metadata": {
        "id": "bpDLN98uAMzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we make sure to install all the needed libraries"
      ],
      "metadata": {
        "id": "JMFrOUcb62Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ZVOMcYmyrr6M",
        "outputId": "300a67d9-25f5-43cb-96e5-eb4b89b7b6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppress warning messages"
      ],
      "metadata": {
        "id": "420baWnu5FuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "3JS6A6DA5EiS"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2 - Build and use a chatbot\n",
        "\n",
        "At this point, we create a conversational pipeline pipeline using blenderbot-400M-distill model from facebook (https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fhuggingface.co%2Ffacebook%2Fblenderbot-400M-distill)\n",
        "You can find also a lot of other conversationals model from Huggingface hub filtering models by Text2Text Generation type (https://huggingface.co/models?pipeline_tag=text2text-generation&sort=trending)"
      ],
      "metadata": {
        "id": "mSgViB5Y8w5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "chatbot = pipeline(task=\"conversational\",\n",
        "                   model=\"facebook/blenderbot-400M-distill\")"
      ],
      "metadata": {
        "id": "pv-8QzoKtOii"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the chatbot is loaded let's pass the user message"
      ],
      "metadata": {
        "id": "a0GDpmas_YsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"\"\"\n",
        "What are some fun activities I can do in the weekend?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NudbNWiYwRBm"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To pass the user message in the chatbot firstly we need to put it in a Conversation object"
      ],
      "metadata": {
        "id": "aUNmbIjQ7YYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Conversation"
      ],
      "metadata": {
        "id": "Jjup1QnHtbUn"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = Conversation(user_message)\n",
        "conversation"
      ],
      "metadata": {
        "id": "CS80-QwHzNw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can pass the conversation to the chatbot"
      ],
      "metadata": {
        "id": "jZQl4OuhDmi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(conversation)\n",
        "conversation"
      ],
      "metadata": {
        "id": "f-8QDCy_Dqg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also try to continue the conversation:"
      ],
      "metadata": {
        "id": "yT3dD0ZY8n3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message_1 = \"\"\"\n",
        "What else do you recommend?\n",
        "\"\"\"\n",
        "conversation_1 = Conversation(user_message_1)\n",
        "conversation_1"
      ],
      "metadata": {
        "id": "d4FW6k_h8xyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the model does not have memory of any prior conversations."
      ],
      "metadata": {
        "id": "Fk6avA0N9Tvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_1 = chatbot(conversation_1)\n",
        "conversation_1"
      ],
      "metadata": {
        "id": "Wc2a5Nq09NdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To include prior conversations in the LLM's context, we can add a 'message' to include the previous chat history."
      ],
      "metadata": {
        "id": "wDpc9ATb9sIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.add_message(\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"\"\"\n",
        "Other then going to the beach or to the lake, what else do you recommend?\n",
        "\"\"\"\n",
        "    })\n",
        "conversation"
      ],
      "metadata": {
        "id": "6672Dabj9yDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_output = chatbot(conversation)\n",
        "conversation_output"
      ],
      "metadata": {
        "id": "Bkyh0Fci-PoY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}